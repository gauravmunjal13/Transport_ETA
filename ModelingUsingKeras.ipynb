{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "# For display\n",
    "%matplotlib inline\n",
    "\n",
    "# Setting format for not to display in scientific notation \n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pre-Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Laod the data\n",
    "raw_df = pd.read_csv(\"PreProcessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42185, 196)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the mappings\n",
    "pickle_file = open('mappings.pickle', 'rb')\n",
    "mappings = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>actual_time_to_travel</th>\n",
       "      <th>time_taken_sofar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9        ...         186  \\\n",
       "0 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00        ...        0.00   \n",
       "1 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00        ...        0.00   \n",
       "2 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00        ...        0.00   \n",
       "3 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00        ...        0.00   \n",
       "4 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00        ...        0.00   \n",
       "\n",
       "   187  188  189  190  191  192  193  actual_time_to_travel  time_taken_sofar  \n",
       "0 0.00 0.00 0.00 0.00 0.00 0.00 0.00                    nan               nan  \n",
       "1 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  10.00              0.00  \n",
       "2 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  51.00             10.00  \n",
       "3 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  20.00             61.00  \n",
       "4 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  10.00             81.00  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the response variable: Actual time to travel between the bus stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f84715959e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFo9JREFUeJzt3X+Q3PV93/HnO8hgB2IkjLkqkqYS\njeKGjMY23AAuncwCqSTAY9EZM5WHiQUlo5mWeNyWjiPqSZnYpsFtHdtkWhyNUSJ7iGVK7KABGqrK\nbDv5AxkTMD9NdMYqHJKRXYHSM40bJe/+sZ+D5bjT7t7t7a70eT5mdvb7fX8/3933fqW9131/7F5k\nJpKk+vzMsBuQJA2HASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmq1JJhN3A8Z599\ndq5evbrn9X7yk59w+umn97+hPrLH/rDH/hj1Hke9PxitHh999NEfZ+a7Ow7MzJG9XXDBBTkfDz30\n0LzWGyR77A977I9R73HU+8scrR6B72QXP2M9BCRJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBI\nUqUMAEmqlAEgSZUa6a+CGLTV2+6ftX7gtqsG3IkkLT73ACSpUgaAJFXKAJCkShkAklQpA0CSKmUA\nSFKlDABJqpQBIEmVMgAkqVIGgCRVqqsAiIilEXFPRHwvIp6NiA9ExFkRsSci9pf7ZWVsRMTtETER\nEU9ExPltj7OljN8fEVsW60VJkjrrdg/gi8CfZubfB94LPAtsA/Zm5lpgb5kHuAJYW25bgTsAIuIs\n4BbgIuBC4Jbp0JAkDV7HAIiIdwK/AtwJkJn/LzNfBTYBO8uwncDVZXoT8JVseRhYGhHLgQ3Answ8\nkpmvAHuAjX19NZKkrnWzB3Au8CPgDyLisYj4ckScDoxl5iGAcn9OGb8CeLFt/clSm6suSRqCyMzj\nD4gYBx4GLsnMfRHxReAvgY9l5tK2ca9k5rKIuB/4ncz8s1LfC3wCuAw4LTM/U+q/BbyWmZ+b8Xxb\naR06Ymxs7IJdu3b1/KKmpqY444wzel7vyZeOzlpft+LMnh+rk/n2OEj22B/2uHCj3h+MVo+XXnrp\no5k53mlcN38PYBKYzMx9Zf4eWsf7X46I5Zl5qBziOdw2flXb+iuBg6XemFFvznyyzNwObAcYHx/P\nRqMxc0hHzWaT+ax33Vx/D+Da3h+rk/n2OEj22B/2uHCj3h+cGD3O1PEQUGb+EHgxIt5TSpcDzwC7\ngekrebYA95bp3cBHy9VAFwNHyyGiB4H1EbGsnPxdX2qSpCHo9i+CfQy4KyJOBZ4HrqcVHndHxA3A\nC8A1ZewDwJXABPBaGUtmHomITwOPlHGfyswjfXkVi8y/FCbpZNRVAGTm48Bsx5Mun2VsAjfO8Tg7\ngB29NChJWhx+EliSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwA\nSaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCk\nSnUVABFxICKejIjHI+I7pXZWROyJiP3lflmpR0TcHhETEfFERJzf9jhbyvj9EbFlcV6SJKkbvewB\nXJqZ78vM8TK/DdibmWuBvWUe4ApgbbltBe6AVmAAtwAXARcCt0yHhiRp8BZyCGgTsLNM7wSubqt/\nJVseBpZGxHJgA7AnM49k5ivAHmDjAp5fkrQA3QZAAv8tIh6NiK2lNpaZhwDK/TmlvgJ4sW3dyVKb\nqy5JGoIlXY67JDMPRsQ5wJ6I+N5xxsYstTxO/c0rtwJmK8DY2BjNZrPLFt8wNTU1r/VuWnesp/Hz\neY5p8+1xkOyxP+xx4Ua9PzgxepypqwDIzIPl/nBEfJPWMfyXI2J5Zh4qh3gOl+GTwKq21VcCB0u9\nMaPenOW5tgPbAcbHx7PRaMwc0lGz2WQ+61237f6exh+4tvfnmDbfHgfJHvvDHhdu1PuDE6PHmToe\nAoqI0yPi56angfXAU8BuYPpKni3AvWV6N/DRcjXQxcDRcojoQWB9RCwrJ3/Xl5okaQi62QMYA74Z\nEdPj/ygz/zQiHgHujogbgBeAa8r4B4ArgQngNeB6gMw8EhGfBh4p4z6VmUf69kokST3pGACZ+Tzw\n3lnq/xu4fJZ6AjfO8Vg7gB29tylJ6jc/CSxJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUM\nAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQ\npEoZAJJUKQNAkiq1ZNgNLKbV2+6ftX7gtqsG3IkkjZ6u9wAi4pSIeCwi7ivzayJiX0Tsj4ivR8Sp\npX5amZ8oy1e3PcbNpf5cRGzo94uRJHWvlz2AjwPPAu8s858FPp+ZuyLiS8ANwB3l/pXM/IWI2FzG\n/ZOIOA/YDPwy8PPAf4+IX8zMv+nTa+naXHsGklSTrvYAImIlcBXw5TIfwGXAPWXITuDqMr2pzFOW\nX17GbwJ2ZeZPM/MHwARwYT9ehCSpd90eAvoC8Angb8v8u4BXM/NYmZ8EVpTpFcCLAGX50TL+9fos\n60iSBqzjIaCI+CBwODMfjYjGdHmWodlh2fHWaX++rcBWgLGxMZrNZqcW32Jqaopms8lN6451HrwA\nv3fXvbPW1604s+O60z2OMnvsD3tcuFHvD06MHmfq5hzAJcCHIuJK4O20zgF8AVgaEUvKb/krgYNl\n/CSwCpiMiCXAmcCRtvq09nVel5nbge0A4+Pj2Wg0en5RzWaTRqPBdUM61n/g2kbHMdM9jjJ77A97\nXLhR7w9OjB5n6ngIKDNvzsyVmbma1kncb2XmtcBDwIfLsC3A9K/Du8s8Zfm3MjNLfXO5SmgNsBb4\ndt9eiSSpJwv5HMBvArsi4jPAY8CdpX4n8NWImKD1m/9mgMx8OiLuBp4BjgE3DuMKIElSS08BkJlN\noFmmn2eWq3gy86+Aa+ZY/1bg1l6blCT1n18FIUmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhS\npQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXK\nAJCkShkAklQpA0CSKmUASFKlOgZARLw9Ir4dEd+NiKcj4rdLfU1E7IuI/RHx9Yg4tdRPK/MTZfnq\ntse6udSfi4gNi/WiJEmddbMH8FPgssx8L/A+YGNEXAx8Fvh8Zq4FXgFuKONvAF7JzF8APl/GERHn\nAZuBXwY2Av85Ik7p54uRJHWvYwBky1SZfVu5JXAZcE+p7wSuLtObyjxl+eUREaW+KzN/mpk/ACaA\nC/vyKiRJPevqHEBEnBIRjwOHgT3A94FXM/NYGTIJrCjTK4AXAcryo8C72uuzrCNJGrAl3QzKzL8B\n3hcRS4FvAr8027ByH3Msm6v+JhGxFdgKMDY2RrPZ7KbFN5mamqLZbHLTumOdBy+Cbnqe7nGU2WN/\n2OPCjXp/cGL0OFNXATAtM1+NiCZwMbA0IpaU3/JXAgfLsElgFTAZEUuAM4EjbfVp7eu0P8d2YDvA\n+Ph4NhqNXloEWj+AG40G1227v+d1++HAtY2OY6Z7HGX22B/2uHCj3h+cGD3O1M1VQO8uv/kTEe8A\nfhV4FngI+HAZtgW4t0zvLvOU5d/KzCz1zeUqoTXAWuDb/XohkqTedLMHsBzYWa7Y+Rng7sy8LyKe\nAXZFxGeAx4A7y/g7ga9GxASt3/w3A2Tm0xFxN/AMcAy4sRxakiQNQccAyMwngPfPUn+eWa7iycy/\nAq6Z47FuBW7tvU1JUr/5SWBJqpQBIEmVMgAkqVIGgCRVygCQpEr19EEwdWf1HB9AO3DbVQPuRJLm\n5h6AJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkipl\nAEhSpQwASaqUASBJlTIAJKlSBoAkVapjAETEqoh4KCKejYinI+LjpX5WROyJiP3lflmpR0TcHhET\nEfFERJzf9lhbyvj9EbFl8V6WJKmTbvYAjgE3ZeYvARcDN0bEecA2YG9mrgX2lnmAK4C15bYVuANa\ngQHcAlwEXAjcMh0akqTB6xgAmXkoM/+8TP8f4FlgBbAJ2FmG7QSuLtObgK9ky8PA0ohYDmwA9mTm\nkcx8BdgDbOzrq5Ekda2ncwARsRp4P7APGMvMQ9AKCeCcMmwF8GLbapOlNlddkjQEkZndDYw4A/gf\nwK2Z+Y2IeDUzl7YtfyUzl0XE/cDvZOaflfpe4BPAZcBpmfmZUv8t4LXM/NyM59lK69ARY2NjF+za\ntavnFzU1NcUZZ5zBky8d7XndQRl7B7z8f1vT61acOdxm5jC9HUeZPfbHqPc46v3BaPV46aWXPpqZ\n453GLenmwSLibcAfA3dl5jdK+eWIWJ6Zh8ohnsOlPgmsalt9JXCw1Bsz6s2Zz5WZ24HtAOPj49lo\nNGYO6ajZbNJoNLhu2/09rzsoN607xueebG3+A9c2htvMHKa34yizx/4Y9R5HvT84MXqcqZurgAK4\nE3g2M3+3bdFuYPpKni3AvW31j5argS4GjpZDRA8C6yNiWTn5u77UJElD0M0ewCXArwFPRsTjpfZv\ngNuAuyPiBuAF4Jqy7AHgSmACeA24HiAzj0TEp4FHyrhPZeaRvrwKSVLPOgZAOZYfcyy+fJbxCdw4\nx2PtAHb00qAkaXH4SWBJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpbr6LiAtrtVz\nfGfRgduuGnAnkmriHoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKTwKP\nMD8hLGkxuQcgSZUyACSpUgaAJFXKAJCkSnUMgIjYERGHI+KpttpZEbEnIvaX+2WlHhFxe0RMRMQT\nEXF+2zpbyvj9EbFlcV6OJKlb3ewB/CGwcUZtG7A3M9cCe8s8wBXA2nLbCtwBrcAAbgEuAi4EbpkO\nDUnScHQMgMz8n8CRGeVNwM4yvRO4uq3+lWx5GFgaEcuBDcCezDySma8Ae3hrqEiSBmi+5wDGMvMQ\nQLk/p9RXAC+2jZsstbnqkqQh6fcHwWKWWh6n/tYHiNhK6/ARY2NjNJvNnpuYmpqi2Wxy07pjPa87\nKGPvYN79zWebzMf0dhxl9tgfo97jqPcHJ0aPM803AF6OiOWZeagc4jlc6pPAqrZxK4GDpd6YUW/O\n9sCZuR3YDjA+Pp6NRmO2YcfVbDZpNBpcN8cnaUfBTeuO8bkn57f5D1zb6G8zc5jejqPMHvtj1Hsc\n9f7gxOhxpvkGwG5gC3Bbub+3rf4bEbGL1gnfoyUkHgT+XduJ3/XAzfNvu25+RYSkfugYABHxNVq/\nvZ8dEZO0rua5Dbg7Im4AXgCuKcMfAK4EJoDXgOsBMvNIRHwaeKSM+1RmzjyxLEkaoI4BkJkfmWPR\n5bOMTeDGOR5nB7Cjp+4kSYvGTwJLUqUMAEmqlAEgSZUyACSpUv5FsJPIXJeHgpeISnor9wAkqVIG\ngCRVygCQpEoZAJJUKQNAkirlVUCV8AvkJM3kHoAkVcoAkKRKeQioch4akurlHoAkVcoAkKRKGQCS\nVCnPAWhWq7fdz03rjnHdjHMEnhuQTh7uAUhSpdwDUE+8akg6eRgA6guDQTrxGABaVAaDNLo8ByBJ\nlRr4HkBEbAS+CJwCfDkzbxt0Dxq+4/35ytm4xyD130ADICJOAf4T8I+ASeCRiNidmc8Msg+deOYK\njD/cePqAO5FOHoPeA7gQmMjM5wEiYhewCTAANC9PvnT0LZ9V6Df3PnSyGnQArABebJufBC4acA9S\nT3o9XDXTbB+oGzXd9jhXGJ4oJ/tHsc9h9hSZuehP8vqTRVwDbMjMXy/zvwZcmJkfaxuzFdhaZt8D\nPDePpzob+PEC211s9tgf9tgfo97jqPcHo9Xj383Md3caNOg9gElgVdv8SuBg+4DM3A5sX8iTRMR3\nMnN8IY+x2OyxP+yxP0a9x1HvD06MHmca9GWgjwBrI2JNRJwKbAZ2D7gHSRID3gPIzGMR8RvAg7Qu\nA92RmU8PsgdJUsvAPweQmQ8ADyzy0yzoENKA2GN/2GN/jHqPo94fnBg9vslATwJLkkaHXwUhSZU6\nqQIgIjZGxHMRMRER24bYx6qIeCgino2IpyPi46V+VkTsiYj95X5ZqUdE3F76fiIizh9gr6dExGMR\ncV+ZXxMR+0qPXy8n64mI08r8RFm+ekD9LY2IeyLie2V7fmDUtmNE/Mvy7/xURHwtIt4+7O0YETsi\n4nBEPNVW63m7RcSWMn5/RGwZQI//ofxbPxER34yIpW3Lbi49PhcRG9rqi/a+n63HtmX/OiIyIs4u\n80PZjguSmSfFjdZJ5e8D5wKnAt8FzhtSL8uB88v0zwF/AZwH/HtgW6lvAz5bpq8E/isQwMXAvgH2\n+q+APwLuK/N3A5vL9JeAf1am/znwpTK9Gfj6gPrbCfx6mT4VWDpK25HWhxt/ALyjbftdN+ztCPwK\ncD7wVFutp+0GnAU8X+6Xlelli9zjemBJmf5sW4/nlff0acCa8l4/ZbHf97P1WOqraF3M8r+As4e5\nHRf0+obdQB//oT4APNg2fzNw87D7Kr3cS+v7j54DlpfacuC5Mv37wEfaxr8+bpH7WgnsBS4D7iv/\ncX/c9gZ8fZuW/+wfKNNLyrhY5P7eWX64xoz6yGxH3vh0+1llu9wHbBiF7QisnvHDtaftBnwE+P22\n+pvGLUaPM5b9Y+CuMv2m9/P0dhzE+362HoF7gPcCB3gjAIa2Hed7O5kOAc32NRMrhtTL68ou/vuB\nfcBYZh4CKPfnlGHD6v0LwCeAvy3z7wJezcxjs/Txeo9l+dEyfjGdC/wI+INymOrLEXE6I7QdM/Ml\n4D8CLwCHaG2XRxmt7Tit1+027PfUP6X1GzXH6WXgPUbEh4CXMvO7MxaNTI/dOpkCIGapDfUSp4g4\nA/hj4F9k5l8eb+gstUXtPSI+CBzOzEe77GMY23cJrd3vOzLz/cBPaB26mMswtuMyWl9ouAb4eeB0\n4Irj9DFy/0+Zu6eh9RoRnwSOAXdNl+boZaA9RsTPAp8E/u1si+foZRT/zYGTKwA6fs3EIEXE22j9\n8L8rM79Ryi9HxPKyfDlwuNSH0fslwIci4gCwi9ZhoC8ASyNi+vMh7X283mNZfiZwZJF7nAQmM3Nf\nmb+HViCM0nb8VeAHmfmjzPxr4BvAP2C0tuO0XrfbUN5T5STpB4FrsxwzGaEe/x6tsP9uee+sBP48\nIv7OCPXYtZMpAEbmayYiIoA7gWcz83fbFu0Gpq8A2ELr3MB0/aPlKoKLgaPTu+qLJTNvzsyVmbma\n1rb6VmZeCzwEfHiOHqd7/3AZv6i/xWTmD4EXI+I9pXQ5ra8OH5ntSOvQz8UR8bPl3326x5HZjm16\n3W4PAusjYlnZ01lfaosmWn8w6jeBD2XmazN631yuoloDrAW+zYDf95n5ZGaek5mry3tnktYFHz9k\nhLZj14Z9EqKfN1pn4f+C1lUBnxxiH/+Q1i7eE8Dj5XYlrWO9e4H95f6sMj5o/aGc7wNPAuMD7rfB\nG1cBnUvrjTUB/BfgtFJ/e5mfKMvPHVBv7wO+U7bln9C6imKktiPw28D3gKeAr9K6UmWo2xH4Gq1z\nEn9N64fUDfPZbrSOw0+U2/UD6HGC1vHy6ffNl9rGf7L0+BxwRVt90d73s/U4Y/kB3jgJPJTtuJCb\nnwSWpEqdTIeAJEk9MAAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASarU/wczFW4NNJcHVgAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8471595198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the historam\n",
    "raw_df['actual_time_to_travel'].hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   36566.00\n",
       "mean      149.20\n",
       "std       141.02\n",
       "min         9.00\n",
       "25%        70.00\n",
       "50%       110.00\n",
       "75%       189.00\n",
       "max      1495.00\n",
       "Name: actual_time_to_travel, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['actual_time_to_travel'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Null Values\n",
    "raw_df['actual_time_to_travel'].hasnans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop Nan values\n",
    "filtered_df = raw_df.dropna(subset=['actual_time_to_travel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36566, 196)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = filtered_df.loc[:,filtered_df.columns != 'actual_time_to_travel']\n",
    "Y = filtered_df.actual_time_to_travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36566, 195)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36566,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `train_test_split` from `sklearn.model_selection`\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>time_taken_sofar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2181.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29453</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4831.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14442</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1922.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20591</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1196.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39011</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1584.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9        ...         \\\n",
       "1964  1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00        ...          \n",
       "29453 0.00 0.00 0.00 1.00 0.00 0.00 0.00 1.00 0.00 0.00        ...          \n",
       "14442 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00        ...          \n",
       "20591 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00        ...          \n",
       "39011 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 1.00        ...          \n",
       "\n",
       "       185  186  187  188  189  190  191  192  193  time_taken_sofar  \n",
       "1964  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00           2181.00  \n",
       "29453 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00           4831.00  \n",
       "14442 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00           1922.00  \n",
       "20591 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00           1196.00  \n",
       "39011 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00           1584.00  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `StandardScaler` from `sklearn.preprocessing`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "# Scale the train set\n",
    "X_train_normalized = scaler.transform(X_train)\n",
    "# Scale the test set\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0178073 , -0.15752192, -0.10211283, -0.94984146, -0.15752192,\n",
       "       -0.40826566,  2.32507632, -0.40277896, -0.40369566, -0.38060607,\n",
       "       -0.41944708, -0.24045922, -0.21789258, -0.10374102, -0.10211283,\n",
       "       -0.11120541, -0.11869572, -0.12010944, -0.11710602, -0.11170842,\n",
       "       -0.11402791, -0.07440841, -0.11678563, -0.11678563, -0.11598099,\n",
       "       -0.11120541, -0.12350093, -0.11885358, -0.12486337, -0.12843018,\n",
       "       -0.12784218, -0.12710361,  7.87678095, -0.12886953, -0.12916165,\n",
       "       -0.13003434, -0.1463423 , -0.13318852, -0.13403675, -0.13361326,\n",
       "       -0.13304666, -0.12650985, -0.04948837, -0.12456181, -0.13333024,\n",
       "       -0.13502009, -0.13219252, -0.12930748, -0.12988927, -0.13032402,\n",
       "       -0.12988927, -0.13190667, -0.13162023, -0.13190667, -0.12930748,\n",
       "       -0.13017926, -0.12531442, -0.11204257, -0.10900019, -0.10762175,\n",
       "       -0.1132047 , -0.11237577, -0.11287382, -0.11662512, -0.11204257,\n",
       "       -0.13389572, -0.11402791, -0.13571842, -0.1072745 , -0.1072745 ,\n",
       "       -0.07341087, -0.11086886, -0.08396743, -0.11419187, -0.10744826,\n",
       "       -0.11120541, -0.11774434, -0.11451914, -0.11533344, -0.11170842,\n",
       "       -0.07085694, -0.09356552, -0.11237577, -0.00854015, -0.12273789,\n",
       "       -0.09336703, -0.05374952, -0.11103726, -0.10640165, -0.0382192 ,\n",
       "       -0.03625527, -0.13627469, -0.18036108, -0.18420514, -0.18818857,\n",
       "       -0.18798073, -0.18787674, -0.17064696, -0.16985324, -0.173901  ,\n",
       "       -0.17278504, -0.17456755, -0.17556319, -0.13219252, -0.16041538,\n",
       "       -0.17289692, -0.14118974, -0.15727863, -0.16431893, -0.16768204,\n",
       "       -0.16814121, -0.16641352, -0.15861254, -0.16722176, -0.16676034,\n",
       "       -0.14424889, -0.15145976, -0.16791177, -0.17523186, -0.16996683,\n",
       "        5.80636927, -0.1717752 , -0.17256108, -0.17534236, -0.15095514,\n",
       "       -0.13696709, -0.11774434, -0.11726591, -0.11806227, -0.10865715,\n",
       "       -0.03675603, -0.37903479, -0.37220889, -0.39848865,  2.53573752,\n",
       "       -0.3936215 , -0.41063337, -0.39411563, -0.270515  ,  0.79010104,\n",
       "       -0.79010104, -0.22460241, -0.35125766,  2.88416064, -0.28371338,\n",
       "       -0.31096108, -0.29765677, -0.30321129, -0.29990129, -0.3009833 ,\n",
       "       -0.30919485, -0.30033441, -0.25803817, -0.09074852, -0.01597861,\n",
       "       -0.01207803, -0.39916421, -0.38648588, -0.40088149,  2.52861755,\n",
       "       -0.40106529, -0.41932686, -0.45385091, -0.16710651, -0.16548552,\n",
       "       -0.13806823, -0.19584492, -0.20051519, -0.18399342, -0.15764343,\n",
       "       -0.18441665, -0.16125049, -0.17222466,  7.27173931, -0.17928054,\n",
       "       -0.14279334, -0.18860364, -0.20286483, -0.20051519, -0.19734562,\n",
       "       -0.20528825, -0.20873647, -0.19189632, -0.20412802, -0.19624606,\n",
       "       -0.20470882, -0.17042052, -0.19913377, -0.19844   , -0.15396025,\n",
       "       -0.18335697, -0.17797632, -0.18870728, -0.17008035,  0.07447228])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train_val_loss(hist):\n",
    "    plt.plot(hist['loss'])\n",
    "    plt.plot(hist['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27424, 195)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer: Same as input_dim with additional one for the bias term \n",
    "model.add(Dense(256, activation='relu', input_dim=195))\n",
    "\n",
    "# Add one hidden layer: One hidden layer is sufficient for majority of the problems\n",
    "# The optimal size of the hidden layer is usually between the size of the input and size of the output layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27424 samples, validate on 9142 samples\n",
      "Epoch 1/50\n",
      "27424/27424 [==============================] - 2s 70us/step - loss: 6059.7903 - val_loss: 28212.8097\n",
      "Epoch 2/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 5856.0499 - val_loss: 27101.8420\n",
      "Epoch 3/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 5578.2037 - val_loss: 25345.9063\n",
      "Epoch 4/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 5453.6020 - val_loss: 24685.3463\n",
      "Epoch 5/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 5303.3863 - val_loss: 24295.6396\n",
      "Epoch 6/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 5235.1181 - val_loss: 26362.0369\n",
      "Epoch 7/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 5118.2377 - val_loss: 26899.9012\n",
      "Epoch 8/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 5016.4877 - val_loss: 25065.7264\n",
      "Epoch 9/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 4846.3601 - val_loss: 27802.2097\n",
      "Epoch 10/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 4798.3169 - val_loss: 26551.8083\n",
      "Epoch 11/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 4597.5109 - val_loss: 27832.3409\n",
      "Epoch 12/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 4558.5965 - val_loss: 26393.4676\n",
      "Epoch 13/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 4381.7438 - val_loss: 30704.1988\n",
      "Epoch 14/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 4246.1496 - val_loss: 28073.6050\n",
      "Epoch 15/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 4058.3353 - val_loss: 27595.5510\n",
      "Epoch 16/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 3991.1210 - val_loss: 32930.9040\n",
      "Epoch 17/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 3932.4452 - val_loss: 29536.1436\n",
      "Epoch 18/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 3669.9023 - val_loss: 35157.7956\n",
      "Epoch 19/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 3544.6470 - val_loss: 28195.6798\n",
      "Epoch 20/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 3390.5031 - val_loss: 27750.1632\n",
      "Epoch 21/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 3288.3030 - val_loss: 28061.6771\n",
      "Epoch 22/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 3178.9018 - val_loss: 33403.6591\n",
      "Epoch 23/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 3025.1845 - val_loss: 32550.3515\n",
      "Epoch 24/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2974.7305 - val_loss: 30863.6668\n",
      "Epoch 25/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2864.4213 - val_loss: 30918.6849\n",
      "Epoch 26/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2683.2497 - val_loss: 29456.9732\n",
      "Epoch 27/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2609.8984 - val_loss: 31816.7389\n",
      "Epoch 28/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2531.0065 - val_loss: 31647.2580\n",
      "Epoch 29/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2341.1980 - val_loss: 34700.1394\n",
      "Epoch 30/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2373.1233 - val_loss: 30205.9290\n",
      "Epoch 31/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2290.5459 - val_loss: 32451.4165\n",
      "Epoch 32/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 2240.9073 - val_loss: 29421.5256\n",
      "Epoch 33/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 2148.5513 - val_loss: 30952.9463\n",
      "Epoch 34/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 2112.5574 - val_loss: 32219.7870\n",
      "Epoch 35/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1984.4980 - val_loss: 35017.8071\n",
      "Epoch 36/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 2008.9834 - val_loss: 28733.3904\n",
      "Epoch 37/50\n",
      "27424/27424 [==============================] - ETA: 0s - loss: 1946.52 - 1s 50us/step - loss: 1949.2911 - val_loss: 35377.1838\n",
      "Epoch 38/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1818.9607 - val_loss: 31604.3182\n",
      "Epoch 39/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1806.6870 - val_loss: 29104.1006\n",
      "Epoch 40/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1762.5738 - val_loss: 31055.3639\n",
      "Epoch 41/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1707.6688 - val_loss: 32901.9325\n",
      "Epoch 42/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1787.3028 - val_loss: 34865.8696\n",
      "Epoch 43/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1805.3039 - val_loss: 32799.8907\n",
      "Epoch 44/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1645.8524 - val_loss: 30121.4489\n",
      "Epoch 45/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1662.8259 - val_loss: 32285.9791\n",
      "Epoch 46/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1561.6941 - val_loss: 32189.4561\n",
      "Epoch 47/50\n",
      "27424/27424 [==============================] - 1s 51us/step - loss: 1578.9671 - val_loss: 31463.9854\n",
      "Epoch 48/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1533.1245 - val_loss: 30722.6808\n",
      "Epoch 49/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1511.6079 - val_loss: 29539.1335\n",
      "Epoch 50/50\n",
      "27424/27424 [==============================] - 1s 50us/step - loss: 1457.1738 - val_loss: 30385.8483\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='Adadelta',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_normalized, Y_train,\n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test_normalized,Y_test),\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-Square: 0.925656893231\n",
      "Test R-Square: -0.598702586612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "Y_pred_train = model.predict(X_train)\n",
    "r2Score = r2_score(Y_train, Y_pred_train) \n",
    "print('Train R-Square:',r2Score)\n",
    "\n",
    "Y_pred_test = model.predict(X_test)\n",
    "r2Score = r2_score(Y_test, Y_pred_test) \n",
    "print('Test R-Square:',r2Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 1500.29630162\n",
      "Test MSE: 30385.8484008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "\n",
    "print('Train MSE:',mse_train)\n",
    "print('Test MSE:',mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_train_val_loss(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit( X_train, Y_train ) # Not on normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 18943.13\n",
      "Variance score: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "Y_pred = lreg.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(Y_test, Y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test_df = pd.DataFrame( data = {'Y_test':Y_test, 'Y_pred':Y_pred} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_pred</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30437</th>\n",
       "      <td>147.00</td>\n",
       "      <td>89.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22166</th>\n",
       "      <td>167.34</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>131.29</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21280</th>\n",
       "      <td>139.38</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24791</th>\n",
       "      <td>173.24</td>\n",
       "      <td>220.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Y_pred  Y_test\n",
       "30437  147.00   89.00\n",
       "22166  167.34   99.00\n",
       "1377   131.29   10.00\n",
       "21280  139.38   90.00\n",
       "24791  173.24  220.00"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_pred</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y_pred</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y_test</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y_pred  Y_test\n",
       "Y_pred    1.00    0.07\n",
       "Y_test    0.07    1.00"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Default values: n_estimators=10, criterion=â€™mseâ€™\n",
    "rfRegr = RandomForestRegressor(random_state = 2)\n",
    "rfRegr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 19881.18\n",
      "Variance score: -0.05\n"
     ]
    }
   ],
   "source": [
    "Y_pred = rfRegr.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(Y_test, Y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
