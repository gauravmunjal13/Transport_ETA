{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "# For display\n",
    "%matplotlib inline\n",
    "\n",
    "# Setting format for not to display in scientific notation \n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pre-Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"PreProcessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41984, 196)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>actual_time_to_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9          ...            \\\n",
       "0 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00          ...             \n",
       "1 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00          ...             \n",
       "2 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00          ...             \n",
       "3 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00          ...             \n",
       "4 1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00          ...             \n",
       "\n",
       "   186  187  188  189  190  191  192  193  194  actual_time_to_travel  \n",
       "0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00                    nan  \n",
       "1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  10.00  \n",
       "2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  51.00  \n",
       "3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  20.00  \n",
       "4 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00                  10.00  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the response variable: Actual time to travel between the bus stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f358afe5898>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGBdJREFUeJzt3X2MXFd5x/HvD+eNxjR2GrJybatr\nlG1LwMIJq8Q0/WOc0MRJEKYSqZxaxKautpUcEVqrxW5VBQiRggoEaEPULXYTXhc3QGMZ09R1MkL8\nkTdDGscxqRfiJhubuNTGsNBG3fTpH/esmd2d2Z3ZnZ3ZnfP7SKOd+9xz7tz7+HqfvS9zjyICMzPL\nz2vavQJmZtYeLgBmZplyATAzy5QLgJlZplwAzMwy5QJgZpYpFwAzs0y5AJiZZcoFwMwsU2e1ewUm\nc9FFF0V3d3dDfX72s59x/vnnz84KzUPOx0TOyVjOx0TzPScHDhz4UUS8fqp2c7oAdHd38+STTzbU\np1wuUyqVZmeF5iHnYyLnZCznY6L5nhNJ/1FPO58CMjPLlAuAmVmmXADMzDLlAmBmlikXADOzTLkA\nmJllygXAzCxTLgBmZplyATAzy9Sc/ibwfNW97RtV40fvurHFa2JmVpuPAMzMMuUCYGaWKRcAM7NM\n1V0AJC2Q9F1Je9L0CkmPSToi6SuSzknxc9P0YJrfXbGM7Sn+nKTrmr0xZmZWv0aOAG4DDldMfxS4\nOyJ6gFPA5hTfDJyKiEuAu1M7JF0KrAfeBKwFPiNpwcxW38zMpquuAiBpGXAj8Nk0LeBq4IHU5H7g\nXen9ujRNmn9Nar8OGIiIVyLieWAQuKIZG2FmZo2r9zbQTwJ/DrwuTf8K8OOIGEnTQ8DS9H4p8CJA\nRIxIOp3aLwUerVhmZZ8zJPUBfQBdXV2Uy+V6twWA4eHhhvs029aVI1Xj7VivuZCPucY5Gcv5mCiX\nnExZACS9AzgREQcklUbDVZrGFPMm6/OLQEQ/0A/Q29sbjY7KMxsj+TR6X/+mWu03lJq1SnWb7yMb\nzQbnZCznY6JcclLPEcBVwDsl3QCcB/wyxRHBIklnpaOAZcCx1H4IWA4MSToLuAA4WREfVdnHzMxa\nbMprABGxPSKWRUQ3xUXchyNiA/AI8O7UbCPwYHq/O02T5j8cEZHi69NdQiuAHuDxpm2JmZk1ZCaP\ngvgAMCDpI8B3gR0pvgP4vKRBir/81wNExCFJu4BngRFgS0S8OoPPNzOzGWioAEREGSin9z+gyl08\nEfE/wE01+t8J3NnoSpqZWfP5m8BmZplyATAzy5QLgJlZplwAzMwy5QJgZpYpFwAzs0y5AJiZZcoF\nwMwsUy4AZmaZcgEwM8uUC4CZWaZcAMzMMuUCYGaWKRcAM7NMuQCYmWXKBcDMLFNTFgBJ50l6XNK/\nSTok6UMpfp+k5yU9lV6rUlySPi1pUNLTki6vWNZGSUfSa2OtzzQzs9lXz4hgrwBXR8SwpLOBb0v6\nZpr3ZxHxwLj211OM99sDXAncC1wp6ULgdqAXCOCApN0RcaoZG2JmZo2pZ1D4iIjhNHl2esUkXdYB\nn0v9HgUWSVoCXAfsi4iT6Zf+PmDtzFbfzMymSxGT/S5PjaQFwAHgEuCeiPiApPuAt1EcIewHtkXE\nK5L2AHdFxLdT3/0UA8iXgPMi4iMp/lfAf0fEx8Z9Vh/QB9DV1fXWgYGBhjZoeHiYhQsXNtRnKgdf\nOl01vnLpBU1pP5tmIx/znXMylvMx0XzPyZo1aw5ERO9U7eoaFD4iXgVWSVoEfF3Sm4HtwA+Bc4B+\nil/yHwZUbRGTxMd/Vn9aHr29vVEqlepZxTPK5TKN9pnKpm3fqBo/uqH65zTafjbNRj7mO+dkLOdj\nolxy0tBdQBHxY6AMrI2I4+k0zyvAPwBXpGZDwPKKbsuAY5PEzcysDeq5C+j16S9/JL0WeDvwvXRe\nH0kC3gU8k7rsBm5JdwOtBk5HxHHgIeBaSYslLQauTTEzM2uDek4BLQHuT9cBXgPsiog9kh6W9HqK\nUztPAX+c2u8FbgAGgZ8D7wWIiJOS7gCeSO0+HBEnm7cpZmbWiCkLQEQ8DVxWJX51jfYBbKkxbyew\ns8F1NDOzWeBvApuZZcoFwMwsUy4AZmaZqut7APNVd6378e+6scVrYmY29/gIwMwsUy4AZmaZcgEw\nM8uUC4CZWaY6+iLwXOOL0mY2l/gIwMwsUy4AZmaZcgEwM8uUC4CZWaZcAMzMMuUCYGaWKRcAM7NM\n1TMk5HmSHpf0b5IOSfpQiq+Q9JikI5K+IumcFD83TQ+m+d0Vy9qe4s9Jum62NsrMzKZWzxHAK8DV\nEfEWYBWwNo31+1Hg7ojoAU4Bm1P7zcCpiLgEuDu1Q9KlwHrgTcBa4DNpmEkzM2uDKQtAFIbT5Nnp\nFcDVwAMpfj/FwPAA69I0af41aeD4dcBARLwSEc9TjBl8RVO2wszMGqZiCN8pGhV/qR8ALgHuAf4a\neDT9lY+k5cA3I+LNkp4B1kbEUJr3feBK4IOpzxdSfEfq88C4z+oD+gC6urreOjAw0NAGDQ8Ps3Dh\nQgAOvnS6apuVSy9oaJmNLqdW+1oaXZ9GVObDCs7JWM7HRPM9J2vWrDkQEb1TtavrWUAR8SqwStIi\n4OvAG6s1Sz9VY16t+PjP6gf6AXp7e6NUKtWzimeUy2VG+2yq9eydDY0ts9Hl1GpfS6Pr04jKfFjB\nORnL+Zgol5w0dBdQRPwYKAOrgUWSRgvIMuBYej8ELAdI8y8ATlbGq/QxM7MWq+cuoNenv/yR9Frg\n7cBh4BHg3anZRuDB9H53mibNfziK80y7gfXpLqEVQA/weLM2xMzMGlPPKaAlwP3pOsBrgF0RsUfS\ns8CApI8A3wV2pPY7gM9LGqT4y389QEQckrQLeBYYAbakU0tmZtYGUxaAiHgauKxK/AdUuYsnIv4H\nuKnGsu4E7mx8Nc3MrNk8IEyFWgO2mJl1Ij8KwswsUy4AZmaZcgEwM8uUC4CZWaZcAMzMMuUCYGaW\nKRcAM7NMuQCYmWXKBcDMLFMuAGZmmXIBMDPLlAuAmVmmXADMzDLlAmBmlikXADOzTNUzJORySY9I\nOizpkKTbUvyDkl6S9FR63VDRZ7ukQUnPSbquIr42xQYlbZudTTIzs3rUMyDMCLA1Ir4j6XXAAUn7\n0ry7I+JjlY0lXUoxDOSbgF8F/lXSr6fZ9wC/QzFA/BOSdkfEs83YEDMza0w9Q0IeB46n9z+VdBhY\nOkmXdcBARLwCPJ/GBh4dOnIwDSWJpIHU1gXAzKwNFBH1N5a6gW8Bbwb+FNgE/AR4kuIo4ZSkvwUe\njYgvpD47gG+mRayNiD9M8fcAV0bEreM+ow/oA+jq6nrrwMBAQxs0PDzMwoULATj40umqbVYuvaBq\nvFb7WmZ7Oc1QmQ8rOCdjOR8TzfecrFmz5kBE9E7Vru4xgSUtBL4KvD8ifiLpXuAOINLPjwN/AKhK\n96D69YYJ1Sci+oF+gN7e3iiVSvWuIgDlcpnRPptqjPF7dEP1ZdZqX8tsL6cZKvNhBedkLOdjolxy\nUlcBkHQ2xS//L0bE1wAi4uWK+X8P7EmTQ8Dyiu7LgGPpfa24mZm12JQFQJKAHcDhiPhERXxJuj4A\n8LvAM+n9buBLkj5BcRG4B3ic4sigR9IK4CWKC8W/36wNaYfuBv/Sb3Q5R++6sSnLNzOrpp4jgKuA\n9wAHJT2VYn8B3CxpFcVpnKPAHwFExCFJuygu7o4AWyLiVQBJtwIPAQuAnRFxqInbYmZmDajnLqBv\nU/28/t5J+twJ3FklvneyfmZm1jr+JrCZWaZcAMzMMuUCYGaWKRcAM7NMuQCYmWXKBcDMLFMuAGZm\nmXIBMDPLlAuAmVmmXADMzDLlAmBmlikXADOzTLkAmJllygXAzCxTLgBmZpmasgBIWi7pEUmHJR2S\ndFuKXyhpn6Qj6efiFJekT0salPS0pMsrlrUxtT8iaePsbZaZmU2lniOAEWBrRLwRWA1skXQpsA3Y\nHxE9wP40DXA9xTCQPUAfcC8UBQO4HbgSuAK4fbRomJlZ601ZACLieER8J73/KXAYWAqsA+5Pze4H\n3pXerwM+F4VHgUWSlgDXAfsi4mREnAL2AWubujVmZla3hq4BSOoGLgMeA7pGB4VPPy9OzZYCL1Z0\nG0qxWnEzM2uDegaFB0DSQuCrwPsj4idStWGCi6ZVYjFJfPzn9FGcOqKrq4tyuVzvKgIwPDx8ps/W\nlSNV2/zNFx+sGt+6sqGPmnWNbns1lfmwgnMylvMxUS45qasASDqb4pf/FyPiayn8sqQlEXE8neI5\nkeJDwPKK7suAYyleGhcvj/+siOgH+gF6e3ujVCqNbzKpcrnMaJ9N277RUN+55uiG0oyXUZkPKzgn\nYzkfE+WSk3ruAhKwAzgcEZ+omLUbGL2TZyPwYEX8lnQ30GrgdDpF9BBwraTF6eLvtSlmZmZtUM8R\nwFXAe4CDkp5Ksb8A7gJ2SdoMvADclObtBW4ABoGfA+8FiIiTku4AnkjtPhwRJ5uyFWZm1rApC0BE\nfJvq5+8BrqnSPoAtNZa1E9jZyAqamdns8DeBzcwy5QJgZpYpFwAzs0y5AJiZZcoFwMwsUy4AZmaZ\ncgEwM8uUC4CZWaZcAMzMMuUCYGaWKRcAM7NMuQCYmWXKBcDMLFN1jwhmc0f3JAPdHL3rxhauiZnN\nZz4CMDPLlAuAmVmm6hkScqekE5KeqYh9UNJLkp5Krxsq5m2XNCjpOUnXVcTXptigpG3N3xQzM2tE\nPUcA9wFrq8TvjohV6bUXQNKlwHrgTanPZyQtkLQAuAe4HrgUuDm1NTOzNqlnSMhvSequc3nrgIGI\neAV4XtIgcEWaNxgRPwCQNJDaPtvwGpuZWVPM5BrArZKeTqeIFqfYUuDFijZDKVYrbmZmbTLd20Dv\nBe4AIv38OPAHVB88PqheaKLagiX1AX0AXV1dlMvlhlZseHj4TJ+tK0ca6jvX1Nr2ybZrfJ/KfFjB\nORnL+Zgol5xMqwBExMuj7yX9PbAnTQ4ByyuaLgOOpfe14uOX3Q/0A/T29kapVGpo3crlMqN9Nk1y\nv/x8cHRDqWp8su0a36cyH1ZwTsZyPibKJSfTOgUkaUnF5O8Co3cI7QbWSzpX0gqgB3gceALokbRC\n0jkUF4p3T3+1zcxspqY8ApD0ZaAEXCRpCLgdKElaRXEa5yjwRwARcUjSLoqLuyPAloh4NS3nVuAh\nYAGwMyIONX1rzMysbvXcBXRzlfCOSdrfCdxZJb4X2NvQ2pmZ2azxs4A6zPjnBG1dOcKmbd/wM4LM\nbAI/CsLMLFMuAGZmmXIBMDPLlAuAmVmmXADMzDLlAmBmlikXADOzTLkAmJllygXAzCxTLgBmZply\nATAzy5QLgJlZplwAzMwy5aeBZmL8U0JH+SmhZvnyEYCZWaamLACSdko6IemZitiFkvZJOpJ+Lk5x\nSfq0pEFJT0u6vKLPxtT+iKSNs7M5ZmZWr3qOAO4D1o6LbQP2R0QPsD9NA1xPMQ5wD9AH3AtFwaAY\nSvJK4Arg9tGiYWZm7VHPkJDfktQ9LryOYpxggPuBMvCBFP9cRATwqKRFaQD5ErAvIk4CSNpHUVS+\nPOMt6GC1ztubmTXDdK8BdEXEcYD08+IUXwq8WNFuKMVqxc3MrE2afReQqsRikvjEBUh9FKeP6Orq\nolwuN7QCw8PDZ/psXTnSUN9O1PXayfPQaH47QeU+Ys5HNbnkZLoF4GVJSyLieDrFcyLFh4DlFe2W\nAcdSvDQuXq624IjoB/oBent7o1QqVWtWU7lcZrTPJp9CYevKET5+sPY/89ENpdatzBxRuY+Y81FN\nLjmZ7img3cDonTwbgQcr4reku4FWA6fTKaKHgGslLU4Xf69NMTMza5MpjwAkfZnir/eLJA1R3M1z\nF7BL0mbgBeCm1HwvcAMwCPwceC9ARJyUdAfwRGr34dELwmZm1h713AV0c41Z11RpG8CWGsvZCexs\naO3MzGzW+JvAZmaZ8rOAMudnBJnly0cAZmaZ8hGANcRHDGadw0cAZmaZcgEwM8uUC4CZWaZcAMzM\nMuUCYGaWKRcAM7NMuQCYmWXKBcDMLFP+Ipg1hb8gZjb/+AjAzCxTLgBmZplyATAzy9SMrgFIOgr8\nFHgVGImIXkkXAl8BuoGjwO9FxClJAj5FMWLYz4FNEfGdmXy+zZ5a5/TNrHM04whgTUSsiojeNL0N\n2B8RPcD+NA1wPdCTXn3AvU34bDMzm6bZuAtoHcUYwgD3A2XgAyn+uTRs5KOSFklakgaNtw7lu4PM\n5q6ZHgEE8C+SDkjqS7Gu0V/q6efFKb4UeLGi71CKmZlZG8z0COCqiDgm6WJgn6TvTdJWVWIxoVFR\nSPoAurq6KJfLDa3Q8PDwmT5bV4401LcTdb12buah0X/XZqrcR8z5qCaXnMyoAETEsfTzhKSvA1cA\nL4+e2pG0BDiRmg8Byyu6LwOOVVlmP9AP0NvbG6VSqaF1KpfLjPbZ5AuZbF05wscPzr3v+x3dUGrb\nZ1fuI+Z8VJNLTqZ9CkjS+ZJeN/oeuBZ4BtgNbEzNNgIPpve7gVtUWA2c9vl/M7P2mcmfhl3A14u7\nOzkL+FJE/LOkJ4BdkjYDLwA3pfZ7KW4BHaS4DfS9M/hsMzOboWkXgIj4AfCWKvH/Aq6pEg9gy3Q/\nz8zMmsvfBDYzy5QLgJlZpube7SGWNX9xzKx1fARgZpYpHwHYvDCdh9P5qMFscj4CMDPLlI8ArC38\nuGmz9vMRgJlZpnwEYB2r1lHGfWvPb/GamM1NPgIwM8uUC4CZWaZ8Csgs8ZfQLDcuAGZTaPSOJRcM\nmy98CsjMLFM+ArDsHHzp9KyOFudTSTZfuACYtZkLhrVLywuApLXAp4AFwGcj4q5Wr4PZfODCYLOt\npQVA0gLgHuB3KAaJf0LS7oh4tpXrYdYOzXr8RbMfo7F15ciEU2IuMnlo9RHAFcBgGk4SSQPAOsAF\nwGwOadadT76Dam5rdQFYCrxYMT0EXNnidTCzJpurRzfTVe2oqNVaUQxbXQBUJRZjGkh9QF+aHJb0\nXIOfcRHwo2msW0d6n/MxgXMylvMx0VzIiT46o+6/Vk+jVheAIWB5xfQy4Fhlg4joB/qn+wGSnoyI\n3un27zTOx0TOyVjOx0S55KTVXwR7AuiRtELSOcB6YHeL18HMzGjxEUBEjEi6FXiI4jbQnRFxqJXr\nYGZmhZZ/DyAi9gJ7Z/Ejpn36qEM5HxM5J2M5HxNlkRNFxNStzMys4/hhcGZmmeqYAiBpraTnJA1K\n2tbu9WkFScslPSLpsKRDkm5L8Qsl7ZN0JP1cnOKS9OmUo6clXd7eLZg9khZI+q6kPWl6haTHUk6+\nkm5CQNK5aXowze9u53rPFkmLJD0g6Xtpf3lbzvuJpD9J/2eekfRlSefluI90RAGoeMTE9cClwM2S\nLm3vWrXECLA1It4IrAa2pO3eBuyPiB5gf5qGIj896dUH3Nv6VW6Z24DDFdMfBe5OOTkFbE7xzcCp\niLgEuDu160SfAv45In4TeAtFbrLcTyQtBd4H9EbEmyluSFlPjvtIRMz7F/A24KGK6e3A9navVxvy\n8CDFc5aeA5ak2BLgufT+74CbK9qfaddJL4rvl+wHrgb2UHwB8UfAWeP3F4o70t6W3p+V2qnd29Dk\nfPwy8Pz47cp1P+EXTyS4MP2b7wGuy3Ef6YgjAKo/YmJpm9alLdJh6WXAY0BXRBwHSD8vTs1yydMn\ngT8H/i9N/wrw44gYSdOV230mJ2n+6dS+k7wB+E/gH9Jpsc9KOp9M95OIeAn4GPACcJzi3/wAGe4j\nnVIApnzERCeTtBD4KvD+iPjJZE2rxDoqT5LeAZyIiAOV4SpNo455neIs4HLg3oi4DPgZvzjdU01H\n5yRd61gHrAB+FTif4rTXeB2/j3RKAZjyEROdStLZFL/8vxgRX0vhlyUtSfOXACdSPIc8XQW8U9JR\nYIDiNNAngUWSRr/3UrndZ3KS5l8AnGzlCrfAEDAUEY+l6QcoCkKu+8nbgecj4j8j4n+BrwG/RYb7\nSKcUgCwfMSFJwA7gcER8omLWbmBjer+R4trAaPyWdJfHauD06CmAThER2yNiWUR0U+wHD0fEBuAR\n4N2p2ficjObq3al9R/x1Nyoifgi8KOk3Uugaikew57qfvACslvRL6f/QaD7y20fafRGiWS/gBuDf\nge8Df9nu9WnRNv82xaHo08BT6XUDxfnJ/cCR9PPC1F4Ud0t9HzhIcRdE27djFvNTAvak928AHgcG\ngX8Ezk3x89L0YJr/hnav9yzlYhXwZNpX/glYnPN+AnwI+B7wDPB54Nwc9xF/E9jMLFOdcgrIzMwa\n5AJgZpYpFwAzs0y5AJiZZcoFwMwsUy4AZmaZcgEwM8uUC4CZWab+HzYUwMhBVinrAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f358afe53c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the historam\n",
    "raw_df['actual_time_to_travel'].hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   36199.00\n",
       "mean      143.84\n",
       "std       119.95\n",
       "min         9.00\n",
       "25%        70.00\n",
       "50%       110.00\n",
       "75%       186.00\n",
       "max       897.00\n",
       "Name: actual_time_to_travel, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['actual_time_to_travel'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Null Values\n",
    "raw_df['actual_time_to_travel'].hasnans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop Nan values\n",
    "filtered_df = raw_df.dropna(subset=['actual_time_to_travel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36199, 196)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = filtered_df.loc[:,filtered_df.columns != 'actual_time_to_travel']\n",
    "Y = filtered_df.actual_time_to_travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36199, 195)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36199,)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `train_test_split` from `sklearn.model_selection`\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24476</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12299</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38290</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9 ...   185  186  187  \\\n",
       "24476 0.00 0.00 0.00 1.00 0.00 1.00 0.00 0.00 0.00 0.00 ...  0.00 0.00 0.00   \n",
       "9540  1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 ...  0.00 0.00 0.00   \n",
       "12299 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 ...  0.00 0.00 0.00   \n",
       "2929  1.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00 ...  0.00 0.00 0.00   \n",
       "38290 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 1.00 ...  0.00 0.00 0.00   \n",
       "\n",
       "       188  189  190  191  192  193  194  \n",
       "24476 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "9540  0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "12299 0.00 0.00 0.00 0.00 1.00 0.00 0.00  \n",
       "2929  0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "38290 0.00 1.00 0.00 0.00 0.00 0.00 0.00  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `StandardScaler` from `sklearn.preprocessing`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "# Scale the train set\n",
    "X_train = scaler.transform(X_train)\n",
    "# Scale the test set\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27149, 195)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer: Same as input_dim with additional one for the bias term \n",
    "model.add(Dense(256, activation='relu', input_dim=195))\n",
    "\n",
    "# Add one hidden layer: One hidden layer is sufficient for majority of the problems\n",
    "# The optimal size of the hidden layer is usually between the size of the input and size of the output layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27149/27149 [==============================] - 1s 54us/step - loss: 16584.3110 - mean_absolute_error: 91.2420\n",
      "Epoch 2/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 14289.1876 - mean_absolute_error: 85.1344\n",
      "Epoch 3/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 14104.0693 - mean_absolute_error: 84.7568\n",
      "Epoch 4/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 14000.4702 - mean_absolute_error: 84.5642\n",
      "Epoch 5/100\n",
      "27149/27149 [==============================] - 1s 32us/step - loss: 13893.9154 - mean_absolute_error: 84.3185\n",
      "Epoch 6/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 13807.1844 - mean_absolute_error: 84.0434\n",
      "Epoch 7/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 13701.1887 - mean_absolute_error: 83.7799\n",
      "Epoch 8/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 13629.8320 - mean_absolute_error: 83.5400\n",
      "Epoch 9/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 13503.2808 - mean_absolute_error: 83.2510\n",
      "Epoch 10/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 13414.6063 - mean_absolute_error: 83.1585\n",
      "Epoch 11/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 13295.5292 - mean_absolute_error: 82.8127\n",
      "Epoch 12/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 13085.9526 - mean_absolute_error: 82.3067\n",
      "Epoch 13/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 12908.8649 - mean_absolute_error: 81.6491\n",
      "Epoch 14/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 12574.9812 - mean_absolute_error: 80.7728\n",
      "Epoch 15/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 12245.3870 - mean_absolute_error: 79.6366\n",
      "Epoch 16/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 11807.0521 - mean_absolute_error: 78.2650\n",
      "Epoch 17/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 11363.1322 - mean_absolute_error: 76.7548\n",
      "Epoch 18/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 10866.3085 - mean_absolute_error: 75.5075\n",
      "Epoch 19/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 10343.8173 - mean_absolute_error: 73.5836\n",
      "Epoch 20/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 9803.2103 - mean_absolute_error: 71.9825\n",
      "Epoch 21/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 9324.7133 - mean_absolute_error: 70.3828\n",
      "Epoch 22/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 8783.0004 - mean_absolute_error: 68.5963\n",
      "Epoch 23/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 8528.1166 - mean_absolute_error: 67.6550\n",
      "Epoch 24/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 8039.4804 - mean_absolute_error: 66.0323\n",
      "Epoch 25/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 7558.7113 - mean_absolute_error: 64.2538\n",
      "Epoch 26/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 7336.8619 - mean_absolute_error: 63.5918\n",
      "Epoch 27/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 7064.9015 - mean_absolute_error: 62.6969\n",
      "Epoch 28/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 6744.8449 - mean_absolute_error: 61.2017\n",
      "Epoch 29/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 6551.7874 - mean_absolute_error: 60.2650\n",
      "Epoch 30/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 6179.0544 - mean_absolute_error: 58.9051\n",
      "Epoch 31/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 6146.5485 - mean_absolute_error: 58.9405\n",
      "Epoch 32/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 5972.6960 - mean_absolute_error: 58.2138\n",
      "Epoch 33/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 5626.4996 - mean_absolute_error: 56.5971\n",
      "Epoch 34/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 5529.1283 - mean_absolute_error: 55.7953\n",
      "Epoch 35/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 5383.1319 - mean_absolute_error: 55.4332\n",
      "Epoch 36/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 5083.9379 - mean_absolute_error: 53.9785\n",
      "Epoch 37/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 5005.6222 - mean_absolute_error: 53.4229\n",
      "Epoch 38/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 4784.5250 - mean_absolute_error: 52.3463\n",
      "Epoch 39/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 4794.5511 - mean_absolute_error: 52.5806\n",
      "Epoch 40/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 4498.2393 - mean_absolute_error: 50.9045\n",
      "Epoch 41/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 4522.1035 - mean_absolute_error: 51.2197\n",
      "Epoch 42/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 4265.1143 - mean_absolute_error: 49.6436\n",
      "Epoch 43/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 4068.4346 - mean_absolute_error: 48.1954\n",
      "Epoch 44/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 4107.1744 - mean_absolute_error: 48.8142\n",
      "Epoch 45/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3828.3468 - mean_absolute_error: 47.2088\n",
      "Epoch 46/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3725.5010 - mean_absolute_error: 46.4853\n",
      "Epoch 47/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3575.3902 - mean_absolute_error: 45.4031\n",
      "Epoch 48/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3485.5060 - mean_absolute_error: 44.9618\n",
      "Epoch 49/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3382.6497 - mean_absolute_error: 44.5094\n",
      "Epoch 50/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3259.8648 - mean_absolute_error: 43.7316\n",
      "Epoch 51/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3094.9946 - mean_absolute_error: 42.4729\n",
      "Epoch 52/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 3011.5908 - mean_absolute_error: 41.7403\n",
      "Epoch 53/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 2918.7760 - mean_absolute_error: 41.0619\n",
      "Epoch 54/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 2798.1252 - mean_absolute_error: 40.2367\n",
      "Epoch 55/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2674.9847 - mean_absolute_error: 39.3116\n",
      "Epoch 56/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2600.3562 - mean_absolute_error: 38.8085\n",
      "Epoch 57/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 2582.5560 - mean_absolute_error: 38.3999\n",
      "Epoch 58/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2505.7672 - mean_absolute_error: 38.2951\n",
      "Epoch 59/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2391.5489 - mean_absolute_error: 37.1092\n",
      "Epoch 60/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 2327.0092 - mean_absolute_error: 36.7155\n",
      "Epoch 61/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2320.3038 - mean_absolute_error: 36.5527\n",
      "Epoch 62/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2192.4519 - mean_absolute_error: 35.2113\n",
      "Epoch 63/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2268.7227 - mean_absolute_error: 34.4518\n",
      "Epoch 64/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 2071.9561 - mean_absolute_error: 34.3440\n",
      "Epoch 65/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 2061.1928 - mean_absolute_error: 34.2824\n",
      "Epoch 66/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 2005.4749 - mean_absolute_error: 33.6757\n",
      "Epoch 67/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1884.5562 - mean_absolute_error: 32.7927\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27149/27149 [==============================] - 1s 33us/step - loss: 1834.7152 - mean_absolute_error: 32.3908\n",
      "Epoch 69/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1801.7397 - mean_absolute_error: 31.8245\n",
      "Epoch 70/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1730.1377 - mean_absolute_error: 31.0595\n",
      "Epoch 71/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1779.2531 - mean_absolute_error: 31.7253\n",
      "Epoch 72/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1695.0309 - mean_absolute_error: 30.9208\n",
      "Epoch 73/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1692.2795 - mean_absolute_error: 30.9113\n",
      "Epoch 74/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1622.6142 - mean_absolute_error: 30.1450\n",
      "Epoch 75/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1615.4535 - mean_absolute_error: 30.0392\n",
      "Epoch 76/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1550.2785 - mean_absolute_error: 29.5094\n",
      "Epoch 77/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1569.4895 - mean_absolute_error: 29.7300\n",
      "Epoch 78/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1551.0010 - mean_absolute_error: 29.3459\n",
      "Epoch 79/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1473.1859 - mean_absolute_error: 28.6949\n",
      "Epoch 80/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1410.6939 - mean_absolute_error: 27.9551\n",
      "Epoch 81/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1396.8505 - mean_absolute_error: 27.8195\n",
      "Epoch 82/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1403.6975 - mean_absolute_error: 27.8185\n",
      "Epoch 83/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1364.7768 - mean_absolute_error: 27.1851\n",
      "Epoch 84/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1340.7405 - mean_absolute_error: 26.8982\n",
      "Epoch 85/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1274.2292 - mean_absolute_error: 26.3249\n",
      "Epoch 86/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1354.2875 - mean_absolute_error: 26.9828\n",
      "Epoch 87/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1256.7805 - mean_absolute_error: 26.1522\n",
      "Epoch 88/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1272.3838 - mean_absolute_error: 26.4062\n",
      "Epoch 89/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1238.1966 - mean_absolute_error: 26.0604\n",
      "Epoch 90/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1204.9732 - mean_absolute_error: 25.7814\n",
      "Epoch 91/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1195.7234 - mean_absolute_error: 25.5272\n",
      "Epoch 92/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1206.7489 - mean_absolute_error: 25.3728\n",
      "Epoch 93/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1115.2495 - mean_absolute_error: 24.5574\n",
      "Epoch 94/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1178.2033 - mean_absolute_error: 25.1364\n",
      "Epoch 95/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1149.4476 - mean_absolute_error: 24.9388\n",
      "Epoch 96/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1095.5036 - mean_absolute_error: 24.2463\n",
      "Epoch 97/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1099.6620 - mean_absolute_error: 24.2449\n",
      "Epoch 98/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1078.5365 - mean_absolute_error: 23.9026\n",
      "Epoch 99/100\n",
      "27149/27149 [==============================] - 1s 33us/step - loss: 1074.0783 - mean_absolute_error: 23.7739\n",
      "Epoch 100/100\n",
      "27149/27149 [==============================] - 1s 34us/step - loss: 1038.1620 - mean_absolute_error: 23.3699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3566e83a58>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,epochs=100, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941744615648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "Y_pred_train = model.predict(X_train)\n",
    "r2Score = r2_score(Y_train, Y_pred_train) \n",
    "print(r2Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832.772625574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "print(mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
