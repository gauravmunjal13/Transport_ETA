{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f9748621e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'application_1522648856070_0187'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.applicationId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/lib/python2.7/site-packages\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from pyspark.sql.functions import col, asc, desc,log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For displaying multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load vehicle tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['vts_jul16_parquet',\n",
       " 'vts_aug16_parquet',\n",
       " 'vts_sep16_parquet',\n",
       " 'vts_oct16_parquet',\n",
       " 'vts_nov16_parquet',\n",
       " 'vts_dec16_parquet',\n",
       " 'vts_jan17_parquet',\n",
       " 'vts_feb17_parquet',\n",
       " 'vts_mar17_parquet',\n",
       " 'vts_apr17_parquet',\n",
       " 'vts_may17_parquet',\n",
       " 'vts_jun17_parquet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"use bmtcvts\")\n",
    "\n",
    "# Laod the VTS data for the duration of jul16 - jun 17\n",
    "months = [\"jul16\", \"aug16\", \"sep16\", \"oct16\", \"nov16\", \"dec16\", \\\n",
    "          \"jan17\", \"feb17\", \"mar17\", \"apr17\", \"may17\", \"jun17\"]\n",
    "#          \"jul17\", \"aug17\", \"sep17\", \"oct17\", \"nov17\", \"dec17\"]\n",
    "\n",
    "all_months = [\"vts_\" + mth + \"_parquet\" for mth in months]\n",
    "all_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are retaining the data frames month by month so we can count rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vts_df = []\n",
    "for index in range(len(all_months)):\n",
    "    sql_query = \"select * from \" + all_months[index]\n",
    "    vts_df.append(sqlContext.sql(sql_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vts_df)\n",
    "type(vts_df)\n",
    "type(vts_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine the data from all months into a single dataframe\n",
    "# Declare a counter to store the number of VTS rows\n",
    "# in each month\n",
    "counter = []\n",
    "\n",
    "# Append all of the data frames into a single DF, via union\n",
    "vts_main_df = vts_df[0]\n",
    "counter.append(vts_df[0].count())\n",
    "for index in range(len(vts_df)-1):\n",
    "    counter.append(vts_df[index+1].count())\n",
    "    vts_main_df = vts_main_df.union(vts_df[index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VTS data accounts to one year from July 2016 to June 2017\n",
    "# vts_main_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1013168409,\n",
       " 1109032457,\n",
       " 974045190,\n",
       " 1061168099,\n",
       " 1040199416,\n",
       " 1095604367,\n",
       " 1067855533,\n",
       " 976218546,\n",
       " 1080027417,\n",
       " 999717643,\n",
       " 1005573387,\n",
       " 984483441]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VTS data by month, staring index corresponds to July 2016 and last index to June 2017\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load static data into Spark dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the waybill trip details for all of 2016-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"use bmtcwaybill\")\n",
    "\n",
    "# Get the waybill details, and clean it\n",
    "waybill_trip_details_df = sqlContext.sql(\"select id,waybill_id,duty_dt,device_id,\\\n",
    "                                          status,schedule_type_id,schedule_no,schedule_name,\\\n",
    "                                          service_type,service_name,trip_number,\\\n",
    "                                          start_point,start_bus_stop_name,end_point,end_bus_stop_name,\\\n",
    "                                          route_id,route_no,distance,start_time,\\\n",
    "                                          act_start_time,etm_start_time,end_time,act_end_time,\\\n",
    "                                          etm_end_time,running_time,is_dread_trip \\\n",
    "                                          from waybill_trip_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter for Jan month\n",
    "# waybill_trip_details_filtered_df = waybill_trip_details_df.filter(((year(waybill_trip_details_df.duty_dt) == 2017) & \\\n",
    "#                                                                      (month(waybill_trip_details_df.duty_dt) == 1)))\n",
    "waybill_trip_details_filtered_df = waybill_trip_details_df.filter(((year(waybill_trip_details_df.duty_dt) == 2016) & \n",
    "                                                                   (month(waybill_trip_details_df.duty_dt) >= 6)) |\n",
    "                                                                  (year(waybill_trip_details_df.duty_dt) == 2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract VTS data for 365R/1-All Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Schedule No. for the Schedule Name 365R/1-All Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the list of all schedule names starting with 365\n",
    "# schedule_365R = waybill_trip_details_filtered_df.filter(col('schedule_name').like(\"%365R%\"))\\\n",
    "# .select(\"schedule_name\").distinct().rdd.map(lambda x:x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# schedule_365R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take schedule 365R/1-All Days, and we see that it takes two schedule no, which corresponds to two form four IDs\n",
    "# waybill_trip_details_filtered_df.filter(col('schedule_name')=='365R/1-All Days')\\\n",
    "# .select(\"schedule_no\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the waybill for data for 365R schedule\n",
    "waybill_trip_details_filtered_365_df = waybill_trip_details_filtered_df.filter(col('schedule_no')==3037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the list of deviceID's that run on 365R\n",
    "device_id_365R_list = waybill_trip_details_filtered_365_df.select('device_id')\\\n",
    ".distinct().rdd.map(lambda x:x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# device_id_365R_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(device_id_365R_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List the buses running on the schedule across the years\n",
    "device_id_365R_list.remove('')\n",
    "#device_id_365R_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Stage 1: \n",
    "From the one-year corpus, take the VTS data for all the device IDs that have run on the 365R/1-All Days schedule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter VTS data for the 365R's deviceID\n",
    "vts_filtered_df = vts_main_df[vts_main_df.device_id.isin(device_id_365R_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112274282"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vts_filtered_df.count()\n",
    "# Count = 112274282"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the results of the stage 1 into the hive table\n",
    "We must run this block across the months and append to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"use bmtc_eta_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the vts data for 365 to hive\n",
    "# Instead of creating a persistent table using saveAsTable, make temp table and dump it as a hive table\n",
    "# vts_filtered_df.createOrReplaceTempView(\"temp_vts_filtered_df\") \n",
    "\n",
    "# The lifetime of this temporary table is tied to the :class:`SparkSession`\n",
    "\n",
    "# Creat a hive table to dump data from temp table\n",
    "# sqlContext.sql(\"create table vts_365R as select * from temp_vts_filtered_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code to append to the exiting table\n",
    "# Filter VTS data for the 365R's deviceID\n",
    "#vts_filtered_feb_df = vts_feb_df[vts_feb_df.device_id.isin(device_id_365R_list)]\n",
    "\n",
    "# Save the vts data for 365 to hive\n",
    "# Instead of creating a persistent table using saveAsTable, make temp table and dump it as a hive table\n",
    "#vts_filtered_feb_df.createOrReplaceTempView(\"temp_vts_filtered_feb_df\") \n",
    "\n",
    "\n",
    "# The lifetime of this temporary table is tied to the :class:`SparkSession`\n",
    "\n",
    "# Create a hive table to dump data from temp table\n",
    "# sqlContext.sql(\"insert into table vts_365r select * from temp_vts_filtered_feb_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|tableName|isTemporary|\n",
      "+---------+-----------+\n",
      "| vts_365r|      false|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+--------------------+\n",
      "|        id|device_id|      lat|longitude|            ist_date|\n",
      "+----------+---------+---------+---------+--------------------+\n",
      "|5867036184|150223075| 12.93866|77.447968|2016-06-30 23:59:...|\n",
      "|5867036363|150814749|12.871403|77.586349|2016-06-30 23:59:...|\n",
      "|5867036504|150221823|13.028916| 77.59285|2016-06-30 23:59:...|\n",
      "|5867036623|150812902|13.026287|77.637184|2016-06-30 23:59:...|\n",
      "|5867036652|150221245|12.903559|77.473869|2016-06-30 23:59:...|\n",
      "|5867036764|150812902|13.026287|77.637184|2016-07-01 00:00:...|\n",
      "|5867036766|150218443|  13.1006|77.594955|2016-06-30 23:59:...|\n",
      "|5867036831|150221245|12.903559|77.473869|2016-06-30 23:59:...|\n",
      "|5867036999|150223075|12.938661|77.447968|2016-06-30 23:59:...|\n",
      "|5867037004|150814749|12.871403|77.586349|2016-06-30 23:59:...|\n",
      "+----------+---------+---------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sqlContext.sql(\"select id, device_id, lat, longitude, ist_date from vts_365r limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "| count(1)|\n",
      "+---------+\n",
      "|112274282|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sqlContext.sql(\"select count(*) from vts_365r\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Stage 2:\n",
    "Building upon the stage 1, remove the rows for the device_id when that bus didn't run on the 365R/1-All Days schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dictionary [key = device id, values = days on which they plied on the schedule]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of days on which a device (bus) plied on the Schedule\n",
    "\n",
    "# The results of this dictionary are saved now.\n",
    "# device_date_mapping = {}\n",
    "\n",
    "# for device_id in device_id_365R_list:\n",
    "#     dates_of_plying_list = waybill_trip_details_filtered_365_df.\\\n",
    "#     filter(waybill_trip_details_filtered_365_df.device_id == device_id).\\\n",
    "#     select(\"duty_dt\").distinct().select(\"duty_dt\").rdd.map(lambda x: x[0]).collect()\n",
    "    \n",
    "#     device_date_mapping[device_id] = dates_of_plying_list\n",
    "\n",
    "# # Save the dictionary: so the next time, we can read directly instead of running it again\n",
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# pickle_file = open('device_date_mapping.pickle', 'wb')\n",
    "# pickle.dump(obj = device_date_mapping, file = pickle_file)\n",
    "# pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bdagr1/pubs/ETA'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load the mappings\n",
    "pickle_file = open('device_date_mapping.pickle', 'rb')\n",
    "device_date_mapping = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVals = sum(len(v) for v in device_date_mapping.itervalues())\n",
    "countVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_list = [v for v in device_date_mapping.itervalues()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this to check if there are multiple buses attached\n",
    "# to a schedule on a given day\n",
    "# from itertools import chain\n",
    "# date_list = list(chain.from_iterable(date_list))\n",
    "# date_list.sort()\n",
    "# date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device_date_mapping_broadcast = sc.broadcast(device_date_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make use of the device_date_mapping dictionary to \n",
    "# eliminate rows from vts_filtered_df for days on\n",
    "# which a device was NOT running the schedule\n",
    "\n",
    "# We do this by iterating over the rows of vts_filtered_df\n",
    "# and applying a function that validates if the \n",
    "# corresponding device_id was assigned the schedule (365R)\n",
    "# on that given date\n",
    "\n",
    "def isValidForDate(device_id, date):\n",
    "    if(device_id in device_date_mapping_broadcast.value):\n",
    "        if(date in device_date_mapping_broadcast.value[device_id]):\n",
    "            return '1'\n",
    "        else:\n",
    "            return '0'\n",
    "    else: \n",
    "        return '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test code\n",
    "# temp_df = vts_filtered_df.limit(4)\n",
    "# temp_df.withColumn(\"Valid\", isValidForDate(temp_df.device_id, temp_df.ist_date)\n",
    "# temp_df.select(\"ist_date\").show()\n",
    "# temp_df = temp_df.withColumn(\"ist_date_part\", date_part)\n",
    "# temp_df.select(\"ist_date\",\"ist_date_part\").show()\n",
    "# temp_df = temp_df.withColumn(\"isValid\", isValidForDateUDF(temp_df.device_id, temp_df.ist_date_part))\n",
    "# temp_df.select(\"device_id\", \"ist_date\",\"ist_date_part\", \"isValid\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime\n",
    "dateTimeFmt = \"yyyy-MM-dd HH:mm:ss.S\"\n",
    "dateFmt = \"yyyy-MM-dd\"\n",
    "\n",
    "date_part = from_unixtime(unix_timestamp('ist_date', format=dateTimeFmt), format=dateFmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "isValidForDateUDF = udf(isValidForDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+\n",
      "|        id|device_id|ign_status|acc_distance|            ist_date|      lat|longitude|vehicle_direction|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+\n",
      "|5867036184|150223075|         1|    19749869|2016-06-30 23:59:...| 12.93866|77.447968|            200.0|\n",
      "|5867036363|150814749|         0|    14960243|2016-06-30 23:59:...|12.871403|77.586349|            136.0|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vts_filtered_stage2_df = vts_filtered_df.select(\"id\", \"device_id\", \"ign_status\", \\\n",
    "                                                        \"acc_distance\", \"ist_date\",  \\\n",
    "                                                        \"lat\", \"longitude\", \"vehicle_direction\")\n",
    "vts_filtered_stage2_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+\n",
      "|        id|device_id|ign_status|acc_distance|            ist_date|      lat|longitude|vehicle_direction|ist_date_part|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+\n",
      "|5867036184|150223075|         1|    19749869|2016-06-30 23:59:...| 12.93866|77.447968|            200.0|   2016-06-30|\n",
      "|5867036363|150814749|         0|    14960243|2016-06-30 23:59:...|12.871403|77.586349|            136.0|   2016-06-30|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vts_filtered_stage2_df = vts_filtered_stage2_df.withColumn(\"ist_date_part\", date_part)\n",
    "vts_filtered_stage2_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "|        id|device_id|ign_status|acc_distance|            ist_date|      lat|longitude|vehicle_direction|ist_date_part|isValid|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "|5867036184|150223075|         1|    19749869|2016-06-30 23:59:...| 12.93866|77.447968|            200.0|   2016-06-30|      0|\n",
      "|5867036363|150814749|         0|    14960243|2016-06-30 23:59:...|12.871403|77.586349|            136.0|   2016-06-30|      0|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vts_filtered_stage2_valid_df = vts_filtered_stage2_df.withColumn(\"isValid\", \n",
    "                                             isValidForDateUDF(vts_filtered_stage2_df.device_id, \n",
    "                                                               vts_filtered_stage2_df.ist_date_part))\n",
    "vts_filtered_stage2_valid_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "|        id|device_id|ign_status|acc_distance|            ist_date|      lat|longitude|vehicle_direction|ist_date_part|isValid|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "|5867192541|150814730|         0|     9201134|2016-07-01 00:12:...|12.790125|77.706451|             40.0|   2016-07-01|      1|\n",
      "|5867355190|150814730|         0|     9201134|2016-07-01 00:27:...|12.790125|77.706451|             40.0|   2016-07-01|      1|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vts_filtered_stage3_df = vts_filtered_stage2_df.where(col(\"isValid\") == '1')\n",
    "vts_filtered_stage2_results_df = vts_filtered_stage2_valid_df.filter(vts_filtered_stage2_valid_df.isValid == '1')\n",
    "vts_filtered_stage2_results_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2787154"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_count = vts_filtered_stage2_results_df.count()\n",
    "stage2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|tableName|isTemporary|\n",
      "+---------+-----------+\n",
      "|vts_365r |false      |\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"use bmtc_eta_default\")\n",
    "sqlContext.sql(\"show tables\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the vts data for 365 to hive\n",
    "# Instead of creating a persistent table using saveAsTable, make temp table and dump it as a hive table\n",
    "vts_filtered_stage2_results_df.createOrReplaceTempView(\"temp_vts_filtered_stage2_results_df\")\n",
    "\n",
    "# To drop the temp view\n",
    "# spark.catalog.dropTempView(\"temp_vts_filtered_stage2_results_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------+\n",
      "|tableName                          |isTemporary|\n",
      "+-----------------------------------+-----------+\n",
      "|vts_365r                           |false      |\n",
      "|temp_vts_filtered_stage2_results_df|true       |\n",
      "+-----------------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"show tables\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "|        id|device_id|ign_status|acc_distance|            ist_date|      lat|longitude|vehicle_direction|ist_date_part|isValid|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "|5867192541|150814730|         0|     9201134|2016-07-01 00:12:...|12.790125|77.706451|             40.0|   2016-07-01|      1|\n",
      "|5867355190|150814730|         0|     9201134|2016-07-01 00:27:...|12.790125|77.706451|             40.0|   2016-07-01|      1|\n",
      "+----------+---------+----------+------------+--------------------+---------+---------+-----------------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from temp_vts_filtered_stage2_results_df limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The lifetime of this temporary table is tied to the :class:`SparkSession`\n",
    "# Create a Hive table to dump data from temp table\n",
    "sqlContext.sql(\"create table vts_365r_filtered as \\\n",
    "               select * from temp_vts_filtered_stage2_results_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'application_1522648856070_0187'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------+\n",
      "|tableName                          |isTemporary|\n",
      "+-----------------------------------+-----------+\n",
      "|vts_365r                           |false      |\n",
      "|vts_365r_filtered                  |false      |\n",
      "|temp_vts_filtered_stage2_results_df|true       |\n",
      "+-----------------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"show tables\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
